{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5841a012",
   "metadata": {},
   "source": [
    "# Report of Project 1: Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef3e34",
   "metadata": {},
   "source": [
    "## Learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d3ac9",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f200d",
   "metadata": {},
   "source": [
    "The agent used in this project is a DuelingDDQN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18438e9f",
   "metadata": {},
   "source": [
    "### Neural Network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b12e3",
   "metadata": {},
   "source": [
    "The neural network architecure is a fully-connected dueling Q-network using two hidden layers (512 and 256 units) and ReLU activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b5d31",
   "metadata": {},
   "source": [
    "### Sampling of experiences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c399944",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344cd4f8",
   "metadata": {},
   "source": [
    "The environment could be solved in 477 episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b45cbb",
   "metadata": {},
   "source": [
    "![Scores](scores.png \"Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323d950",
   "metadata": {},
   "source": [
    "## Ideas for future work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef067b",
   "metadata": {},
   "source": [
    "### Software architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da75a4",
   "metadata": {},
   "source": [
    "From an architectural perspective, loose coupling between the `DuelingDDQN` agent, the `DuelingDenseQNetwork`s, `ReplayBuffer`, `Adam` optimizer, `SmoothL1Loss`, etc. should be preferred to enable composing and testing different implementations without changing the code. \n",
    "\n",
    "Moreover, the action-selection code should be moved into it's own class, decoupling the code even further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4dc01",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c76f4",
   "metadata": {},
   "source": [
    "There are many ways to improve the algorithms and models even further. A (incomplete) list of possible future improvements/extensions are:\n",
    "\n",
    "* Implement Prioritized Experience Replay (PER)\n",
    "* Distributional DQN\n",
    "* Noisy DQN\n",
    "* Rainbow DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a9be73",
   "metadata": {},
   "source": [
    "Also, it would be interesting to see how Bayesian variants (BNNs) of the implemented neural network architecutes could possibly improve the decision making, based on e.g. posterior-predictive distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5774d",
   "metadata": {},
   "source": [
    "Instead of manually testing different hyper-parameter settings, utilization of hyper-parameter optimization tools should be done (e.g. using bayesian optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea1280",
   "metadata": {},
   "source": [
    "### Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d07b2",
   "metadata": {},
   "source": [
    "It would be interesting to test the agent's performance with other (Unity) environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65276415",
   "metadata": {},
   "source": [
    "## Additional References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b75bd",
   "metadata": {},
   "source": [
    "* [Miguel Morales, \"Grokking Deep Reinforcement Learning\" Manning Publications.](https://www.manning.com/books/grokking-deep-reinforcement-learning)\n",
    "* [Mnih, Volodymyr, et al. \"Human-level control through deep reinforcement learning.\" Nature518.7540 (2015): 529.]( http://www.davidqiu.com:8888/research/nature14236.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba44096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
